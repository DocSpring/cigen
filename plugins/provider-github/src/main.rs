/// GitHub Actions Provider Plugin for CIGen
use anyhow::{Context, Result};
use cigen::plugin::protocol::{diagnostic, plugin_server::Plugin, *};
use serde_yaml::{Mapping, Value};
use std::collections::{BTreeMap, HashMap};
use tonic::{Request, Response, Status};

/// Plugin version and metadata
const PLUGIN_NAME: &str = "provider/github";
const PLUGIN_VERSION: &str = "0.1.0";
const PROTOCOL_VERSION: u32 = 1;

/// GitHub Actions provider plugin
#[derive(Debug, Default)]
pub struct GitHubProvider {}

#[tonic::async_trait]
impl Plugin for GitHubProvider {
    async fn handshake(&self, request: Request<Hello>) -> Result<Response<PluginInfo>, Status> {
        let hello = request.into_inner();

        // Verify protocol compatibility
        if hello.core_protocol != PROTOCOL_VERSION {
            return Err(Status::failed_precondition(format!(
                "Protocol version mismatch: core={}, plugin={}",
                hello.core_protocol, PROTOCOL_VERSION
            )));
        }

        tracing::info!(
            "Handshake from core version {} (protocol {})",
            hello.core_version,
            hello.core_protocol
        );

        let info = PluginInfo {
            name: PLUGIN_NAME.to_string(),
            version: PLUGIN_VERSION.to_string(),
            protocol: PROTOCOL_VERSION,
            capabilities: vec![
                "provider:github".to_string(),
                "cache:native".to_string(),
                "matrix:build".to_string(),
            ],
            requires: vec![],
            conflicts_with: vec!["provider:*".to_string()],
            metadata: std::collections::HashMap::new(),
        };

        Ok(Response::new(info))
    }

    async fn detect(
        &self,
        request: Request<DetectRequest>,
    ) -> Result<Response<DetectResult>, Status> {
        let _req = request.into_inner();

        // For now, we don't auto-detect GitHub Actions
        // Later, we could check for .github/workflows/ directory
        let result = DetectResult {
            signals: vec![],
            facts: std::collections::HashMap::new(),
            confidence: 0.0,
            diagnostics: vec![],
        };

        Ok(Response::new(result))
    }

    async fn plan(&self, request: Request<PlanRequest>) -> Result<Response<PlanResult>, Status> {
        let _req = request.into_inner();

        // TODO: Implement planning logic
        // For now, just return empty result
        let result = PlanResult {
            resources: vec![],
            deps: vec![],
            diagnostics: vec![],
        };

        Ok(Response::new(result))
    }

    async fn generate(
        &self,
        request: Request<GenerateRequest>,
    ) -> Result<Response<GenerateResult>, Status> {
        let req = request.into_inner();

        tracing::info!(
            "Generating GitHub Actions config for target: {}",
            req.target
        );

        // TODO: Call the existing GitHub Actions generator
        // For now, return a simple test fragment
        let fragment = Fragment {
            path: ".github/workflows/ci.yml".to_string(),
            content: "# Generated by cigen-provider-github\nname: CI\n".to_string(),
            strategy: MergeStrategy::Replace as i32,
            order: 0,
            format: "yaml".to_string(),
        };

        let result = GenerateResult {
            fragments: vec![fragment],
            diagnostics: vec![],
        };

        Ok(Response::new(result))
    }

    async fn validate(
        &self,
        request: Request<ValidateRequest>,
    ) -> Result<Response<ValidateResult>, Status> {
        let _req = request.into_inner();

        // TODO: Implement validation logic
        let result = ValidateResult {
            diagnostics: vec![],
        };

        Ok(Response::new(result))
    }

    async fn preflight(
        &self,
        request: Request<PreflightRequest>,
    ) -> Result<Response<PreflightResult>, Status> {
        let _req = request.into_inner();

        // LIMITATION: Preflight logic is not yet implemented!
        // Currently ALL jobs will run (no cache/skip optimizations).
        // This means:
        // 1. Jobs will not skip based on unchanged file hashes
        // 2. Work signature caching is not active
        // 3. CI runs will be slower until this is implemented
        //
        // TODO: Implement work signature-based job skipping
        // - Compute hash of job inputs (files, env, package versions)
        // - Compare to cached signatures
        // - Set should_run=false if signatures match
        // - Populate new_signature with computed hash
        tracing::warn!(
            "Preflight check bypassed - job skipping not implemented, all jobs will run"
        );

        let result = PreflightResult {
            should_run: true, // Always run until preflight is implemented
            reason: "preflight_not_implemented".to_string(),
            new_signature: vec![],
        };

        Ok(Response::new(result))
    }
}

fn main() -> Result<()> {
    // Initialize logging to stderr (stdout is used for protobuf messages)
    // Note: Use underscores in environment variable (e.g., RUST_LOG=cigen_provider_github=debug)
    // even though the plugin name uses slashes (provider/github)
    tracing_subscriber::fmt()
        .with_writer(std::io::stderr)
        .with_env_filter(
            tracing_subscriber::EnvFilter::from_default_env()
                .add_directive("cigen_provider_github=info".parse()?),
        )
        .with_target(false)
        .without_time()
        .init();

    tracing::info!("Starting {} v{}", PLUGIN_NAME, PLUGIN_VERSION);

    // Use simple stdio communication with length-prefixed framing
    // Phase 1: Just handle handshake, exit after
    // Phase 2: Message loop for multiple requests

    use cigen::plugin::framing::{receive_message, send_message};
    use std::io::{stdin, stdout};

    // Read Hello message from stdin
    let hello: Hello = receive_message(&mut stdin().lock())?;

    tracing::info!(
        "Received handshake from core version {} (protocol {})",
        hello.core_version,
        hello.core_protocol
    );

    // Verify protocol compatibility
    if hello.core_protocol != PROTOCOL_VERSION {
        anyhow::bail!(
            "Protocol version mismatch: core={}, plugin={}",
            hello.core_protocol,
            PROTOCOL_VERSION
        );
    }

    // Send PluginInfo response
    let info = PluginInfo {
        name: PLUGIN_NAME.to_string(),
        version: PLUGIN_VERSION.to_string(),
        protocol: PROTOCOL_VERSION,
        capabilities: vec![
            "provider:github".to_string(),
            "cache:native".to_string(),
            "matrix:build".to_string(),
        ],
        requires: vec![],
        conflicts_with: vec!["provider:*".to_string()],
        metadata: std::collections::HashMap::new(),
    };

    send_message(&info, &mut stdout().lock())?;

    tracing::info!("Handshake successful, plugin info sent");

    // Message loop: handle Plan and Generate requests
    tracing::info!("Entering message loop...");

    let mut stdin = stdin().lock();
    let mut stdout = stdout().lock();

    loop {
        match receive_message::<PlanRequest, _>(&mut stdin) {
            Ok(_plan_req) => {
                tracing::info!("Received PlanRequest");

                let plan_result = PlanResult {
                    resources: vec![],
                    deps: vec![],
                    diagnostics: vec![],
                };

                send_message(&plan_result, &mut stdout)?;
                tracing::info!("Sent PlanResult");
            }
            Err(e) => {
                tracing::warn!("Stopping plugin loop: {e}");
                break;
            }
        }

        match receive_message::<GenerateRequest, _>(&mut stdin) {
            Ok(gen_req) => {
                tracing::info!("Received GenerateRequest for target: {}", gen_req.target);

                let gen_result = build_generate_result(&gen_req);

                tracing::info!(
                    "Sending GenerateResult with {} fragment(s)",
                    gen_result.fragments.len()
                );
                send_message(&gen_result, &mut stdout)?;
            }
            Err(e) => {
                tracing::warn!("Failed to receive GenerateRequest: {e}");
                break;
            }
        }
    }

    tracing::info!("Plugin loop terminated");
    Ok(())
}

fn build_generate_result(req: &GenerateRequest) -> GenerateResult {
    let schema = match &req.schema {
        Some(schema) => schema,
        None => {
            return GenerateResult {
                fragments: vec![],
                diagnostics: vec![make_diagnostic(
                    "unknown",
                    anyhow::anyhow!("GenerateRequest missing schema"),
                )],
            };
        }
    };
    let (fragments, diagnostics) = build_workflow_fragments(schema);
    GenerateResult {
        fragments,
        diagnostics,
    }
}

fn build_workflow_fragments(schema: &CigenSchema) -> (Vec<Fragment>, Vec<Diagnostic>) {
    let mut diagnostics = Vec::new();

    let workflow_metadata = parse_workflow_metadata(schema, &mut diagnostics);
    let mut jobs_by_workflow: BTreeMap<String, Vec<JobDefinition>> = BTreeMap::new();
    for job in &schema.jobs {
        let workflow = if job.workflow.is_empty() {
            "ci"
        } else {
            &job.workflow
        };
        jobs_by_workflow
            .entry(workflow.to_string())
            .or_default()
            .push(job.clone());
    }

    let mut fragments = Vec::new();

    for (workflow_name, mut jobs) in jobs_by_workflow {
        jobs.sort_by(|a, b| a.id.cmp(&b.id));
        let metadata = workflow_metadata.get(&workflow_name);
        match render_workflow_file(&workflow_name, &jobs, metadata) {
            Ok(content) => fragments.push(Fragment {
                path: format!(".github/workflows/{workflow_name}.yml"),
                content,
                strategy: MergeStrategy::Replace as i32,
                order: 0,
                format: "yaml".to_string(),
            }),
            Err(error) => diagnostics.push(make_diagnostic(&workflow_name, error)),
        }
    }

    (fragments, diagnostics)
}

fn parse_workflow_metadata(
    schema: &CigenSchema,
    diagnostics: &mut Vec<Diagnostic>,
) -> HashMap<String, Mapping> {
    let mut result = HashMap::new();
    for workflow in &schema.workflows {
        match serde_yaml::from_str::<Value>(&workflow.yaml) {
            Ok(Value::Mapping(mapping)) => {
                result.insert(workflow.id.clone(), mapping);
            }
            Ok(other) => diagnostics.push(make_diagnostic(
                &workflow.id,
                anyhow::anyhow!(
                    "Expected mapping for workflow metadata but found {:?}",
                    other
                ),
            )),
            Err(err) => diagnostics.push(make_diagnostic(
                &workflow.id,
                anyhow::anyhow!("Failed to parse workflow metadata: {err}"),
            )),
        }
    }
    result
}

fn render_workflow_file(
    workflow_name: &str,
    jobs: &[JobDefinition],
    metadata: Option<&Mapping>,
) -> anyhow::Result<String> {
    let mut workflow_map = metadata.cloned().unwrap_or_else(Mapping::new);
    let jobs_key = Value::String("jobs".into());
    workflow_map.remove(&jobs_key);

    let name_key = Value::String("name".into());
    if !workflow_map.contains_key(&name_key) {
        workflow_map.insert(
            name_key.clone(),
            Value::String(workflow_name.to_uppercase()),
        );
    }

    let on_key = Value::String("on".into());
    if !workflow_map.contains_key(&on_key) {
        workflow_map.insert(on_key, default_on_value());
    }

    let jobs_mapping = build_jobs_mapping(workflow_name, jobs)?;
    workflow_map.insert(Value::String("jobs".into()), Value::Mapping(jobs_mapping));

    let mut yaml = String::from("# DO NOT EDIT - This file is generated by cigen\n");
    yaml.push_str("# Source: .cigen/workflows/\n");
    yaml.push_str("# Regenerate with: cargo run -- generate --file .cigen\n");
    yaml.push_str("#\n");

    let rendered = serde_yaml::to_string(&workflow_map)
        .with_context(|| format!("Failed to serialize workflow {workflow_name}"))?;
    yaml.push_str(&rendered);
    Ok(yaml)
}

fn default_on_value() -> Value {
    let mut push_mapping = Mapping::new();
    push_mapping.insert(
        Value::String("branches".into()),
        Value::Sequence(vec![Value::String("main".into())]),
    );

    let mut on_mapping = Mapping::new();
    on_mapping.insert(
        Value::String("pull_request".into()),
        Value::Mapping(Mapping::new()),
    );
    on_mapping.insert(Value::String("push".into()), Value::Mapping(push_mapping));
    Value::Mapping(on_mapping)
}

fn build_jobs_mapping(workflow_name: &str, jobs: &[JobDefinition]) -> anyhow::Result<Mapping> {
    let mut mapping = Mapping::new();
    let has_builder = jobs.iter().any(|job| job.id == "build_cigen");
    for job in jobs {
        let rendered = render_job(job, workflow_name, has_builder)?;
        mapping.insert(Value::String(job.id.clone()), Value::Mapping(rendered));
    }
    Ok(mapping)
}

fn render_job(
    job: &JobDefinition,
    _workflow_name: &str,
    has_builder: bool,
) -> anyhow::Result<Mapping> {
    let mut job_map = Mapping::new();

    for (key, value_yaml) in &job.extra {
        job_map.insert(Value::String(key.clone()), parse_yaml_value(value_yaml));
    }

    let runs_on_key = Value::String("runs-on".into());
    if !job_map.contains_key(&runs_on_key) {
        let (runs_on, container) = determine_runner(&job.image);
        if let Some(runs_on_value) = runs_on {
            job_map.insert(runs_on_key.clone(), runs_on_value);
        }
        if let Some(container_value) = container {
            job_map.insert(Value::String("container".into()), container_value);
        }
    }

    if !job.needs.is_empty() {
        job_map.insert(
            Value::String("needs".into()),
            Value::Sequence(job.needs.iter().cloned().map(Value::String).collect()),
        );
    }

    if has_builder && job.id != "build_cigen" {
        let needs_key = Value::String("needs".into());
        match job_map.get_mut(&needs_key) {
            Some(Value::Sequence(seq)) => {
                if !seq
                    .iter()
                    .any(|value| matches!(value, Value::String(s) if s == "build_cigen"))
                {
                    seq.push(Value::String("build_cigen".into()));
                }
            }
            _ => {
                job_map.insert(
                    needs_key,
                    Value::Sequence(vec![Value::String("build_cigen".into())]),
                );
            }
        }
    }

    if !job.env.is_empty() {
        let env_key = Value::String("env".into());
        if !job_map.contains_key(&env_key) {
            job_map.insert(env_key, map_from_string_map(&job.env));
        }
    }

    tracing::debug!("Job {} source_files: {:?}", job.id, job.source_files);
    let skip_flow = if job.id == "build_cigen" {
        None
    } else {
        Some(build_skip_flow(&job.id))
    };

    let package_cache_steps = build_package_cache_steps(job);

    let mut requires_node_runtime = skip_flow.is_some() || !package_cache_steps.is_empty();
    if !requires_node_runtime {
        for step in &job.steps {
            if let Some(step_type) = &step.step_type
                && step_requires_node(step_type)
            {
                requires_node_runtime = true;
                break;
            }
        }
    }

    let mut steps: Vec<Value> = Vec::new();

    if requires_node_runtime {
        steps.push(Value::Mapping(install_node_runtime_step()));
    }

    if job.id != "build_cigen" {
        steps.push(Value::Mapping(install_protobuf_step()));
    }

    let checkout_step = build_checkout_step(job);
    steps.push(Value::Mapping(checkout_step));

    if skip_flow.is_some() && job.id != "build_cigen" {
        steps.push(Value::Mapping(download_cigen_step()));
        steps.push(Value::Mapping(make_cigen_executable_step()));
    }

    if let Some(flow) = &skip_flow {
        steps.push(Value::Mapping(flow.compute_step.clone()));
        steps.push(Value::Mapping(flow.restore_step.clone()));
        steps.push(Value::Mapping(flow.skip_step.clone()));
    }

    let skip_condition = skip_flow.as_ref().map(|flow| flow.condition.as_str());

    for mut cache_step in package_cache_steps.into_iter() {
        if let Some(condition) = skip_condition {
            apply_condition(&mut cache_step, condition);
        }
        steps.push(Value::Mapping(cache_step));
    }

    for step in &job.steps {
        if let Some(step_type) = &step.step_type {
            let mut rendered = match step_type {
                step::StepType::Run(run) => convert_run_step(run),
                step::StepType::Uses(uses) => convert_uses_step(uses),
                step::StepType::RestoreCache(_) | step::StepType::SaveCache(_) => {
                    continue;
                }
            };
            if let Some(condition) = skip_condition {
                apply_condition(&mut rendered, condition);
            }
            steps.push(Value::Mapping(rendered));
        }
    }

    if let Some(flow) = skip_flow {
        steps.push(Value::Mapping(flow.record_step));
    }

    job_map.insert(Value::String("steps".into()), Value::Sequence(steps));

    Ok(job_map)
}

fn determine_runner(image: &str) -> (Option<Value>, Option<Value>) {
    if image.trim().is_empty() {
        return (Some(Value::String("ubuntu-latest".into())), None);
    }

    if image.trim().starts_with("${{") {
        return (Some(Value::String(image.to_string())), None);
    }

    if image.starts_with("ubuntu") || image.starts_with("macos") || image.starts_with("windows") {
        return (Some(Value::String(image.to_string())), None);
    }

    let mut container = Mapping::new();
    container.insert(
        Value::String("image".into()),
        Value::String(image.to_string()),
    );
    (
        Some(Value::String("ubuntu-latest".into())),
        Some(Value::Mapping(container)),
    )
}

struct SkipFlow {
    compute_step: Mapping,
    restore_step: Mapping,
    skip_step: Mapping,
    record_step: Mapping,
    condition: String,
}

fn build_skip_flow(job_id: &str) -> SkipFlow {
    let compute_script = format!(
        concat!(
            "set -euo pipefail\n",
            "mkdir -p .cigen/skip-cache\n",
            "mkdir -p .cigen/cache\n",
            "./.cigen/bin/cigen hash \\\n",
            "  --job {job_id} \\\n",
            "  --config .cigen \\\n",
            "  --base-dir . \\\n",
            "  --output job_hash \\\n",
            "  --cache .cigen/cache/file-hashes.json\n"
        ),
        job_id = job_id
    );

    let mut compute_step = Mapping::new();
    compute_step.insert(
        Value::String("name".into()),
        Value::String("Compute source hash".into()),
    );
    compute_step.insert(
        Value::String("id".into()),
        Value::String("compute_hash".into()),
    );
    compute_step.insert(Value::String("run".into()), Value::String(compute_script));

    let mut cache_with = Mapping::new();
    cache_with.insert(
        Value::String("path".into()),
        Value::String(format!(".cigen/skip-cache/{job_id}")),
    );
    cache_with.insert(
        Value::String("key".into()),
        Value::String(format!(
            "job-skip-${{ runner.os }}-{job_id}-${{ steps.compute_hash.outputs.job_hash }}"
        )),
    );
    cache_with.insert(
        Value::String("restore-keys".into()),
        Value::String(format!("job-skip-${{ runner.os }}-{job_id}-")),
    );

    let mut restore_step = Mapping::new();
    restore_step.insert(
        Value::String("name".into()),
        Value::String("Restore skip cache".into()),
    );
    restore_step.insert(
        Value::String("id".into()),
        Value::String("job_skip_cache".into()),
    );
    restore_step.insert(
        Value::String("uses".into()),
        Value::String("actions/cache@v4".into()),
    );
    restore_step.insert(Value::String("with".into()), Value::Mapping(cache_with));
    restore_step.insert(
        Value::String("if".into()),
        Value::String("${{ env.ACT != 'true' }}".into()),
    );

    let condition = "steps.job_skip_cache.outputs.cache-hit != 'true'".to_string();

    let mut record_step = Mapping::new();
    record_step.insert(
        Value::String("name".into()),
        Value::String("Record job completion".into()),
    );
    record_step.insert(
        Value::String("if".into()),
        Value::String(format!("success() && {condition}")),
    );
    record_step.insert(
        Value::String("run".into()),
        Value::String(format!(
            "set -e
HASH=\"${{JOB_HASH}}\"
if [ -z \"$HASH\" ]; then
  echo 'JOB_HASH missing' >&2
  exit 1
fi
MARKER=.cigen/skip-cache/{job_id}/$HASH
mkdir -p \"$(dirname \"$MARKER\")\"
date > \"$MARKER\"
"
        )),
    );

    let mut record_env = Mapping::new();
    record_env.insert(
        Value::String("JOB_HASH".into()),
        Value::String("${{ steps.compute_hash.outputs.job_hash }}".into()),
    );
    record_step.insert(Value::String("env".into()), Value::Mapping(record_env));

    let mut skip_step = Mapping::new();
    skip_step.insert(
        Value::String("name".into()),
        Value::String("Skip job (cached)".into()),
    );
    skip_step.insert(
        Value::String("if".into()),
        Value::String("steps.job_skip_cache.outputs.cache-hit == 'true'".into()),
    );
    skip_step.insert(
        Value::String("run".into()),
        Value::String("echo 'Job cache hit; skipping remaining steps.' && exit 0".into()),
    );

    SkipFlow {
        compute_step,
        restore_step,
        skip_step,
        record_step,
        condition,
    }
}

fn build_checkout_step(job: &JobDefinition) -> Mapping {
    let mut step = Mapping::new();
    step.insert(
        Value::String("name".into()),
        Value::String("Checkout repository".into()),
    );
    step.insert(
        Value::String("uses".into()),
        Value::String("actions/checkout@v4".into()),
    );

    if !job.checkout.is_empty() {
        let mut with_mapping = Mapping::new();
        for (key, value) in &job.checkout {
            with_mapping.insert(Value::String(key.clone()), parse_yaml_value(value));
        }
        step.insert(Value::String("with".into()), Value::Mapping(with_mapping));
    }

    step
}

fn download_cigen_step() -> Mapping {
    let mut step = Mapping::new();
    step.insert(
        Value::String("name".into()),
        Value::String("Download cigen binary".into()),
    );
    step.insert(
        Value::String("uses".into()),
        Value::String("actions/download-artifact@v4".into()),
    );
    let mut with = Mapping::new();
    with.insert(
        Value::String("name".into()),
        Value::String("cigen-bin".into()),
    );
    with.insert(
        Value::String("path".into()),
        Value::String(".cigen/bin".into()),
    );
    step.insert(Value::String("with".into()), Value::Mapping(with));
    step
}

fn make_cigen_executable_step() -> Mapping {
    let mut step = Mapping::new();
    step.insert(
        Value::String("name".into()),
        Value::String("Prepare cigen binary".into()),
    );
    step.insert(
        Value::String("run".into()),
        Value::String("set -e\nmkdir -p .cigen/bin\nchmod +x .cigen/bin/cigen\n".into()),
    );
    step
}

fn install_node_runtime_step() -> Mapping {
    let mut step = Mapping::new();
    step.insert(
        Value::String("name".into()),
        Value::String("Prepare Node runtime for actions".into()),
    );
    step.insert(
        Value::String("if".into()),
        Value::String("${{ env.ACT == 'true' }}".into()),
    );
    step.insert(
        Value::String("run".into()),
        Value::String(
            "set -e\nif ! command -v node >/dev/null 2>&1 || ! command -v protoc >/dev/null 2>&1; then\n  apt-get update\n  apt-get install -y nodejs npm protobuf-compiler\nfi\n"
                .into(),
        ),
    );
    step
}

fn install_protobuf_step() -> Mapping {
    let mut step = Mapping::new();
    step.insert(
        Value::String("name".into()),
        Value::String("Install protobuf compiler".into()),
    );
    step.insert(
        Value::String("if".into()),
        Value::String("runner.os == 'Linux'".into()),
    );
    let script = "set -e\nif command -v sudo >/dev/null 2>&1; then\n  sudo apt-get update\n  sudo apt-get install -y protobuf-compiler\nelse\n  apt-get update\n  apt-get install -y protobuf-compiler\nfi\n";
    step.insert(Value::String("run".into()), Value::String(script.into()));
    step
}

fn build_package_cache_steps(job: &JobDefinition) -> Vec<Mapping> {
    let mut steps = Vec::new();

    if job.packages.iter().any(|pkg| pkg == "rust") {
        let mut with = Mapping::new();
        with.insert(
            Value::String("path".into()),
            Value::String("~/.cargo/registry\n~/.cargo/git\ntarget".into()),
        );
        with.insert(
            Value::String("key".into()),
            Value::String("${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}".into()),
        );
        with.insert(
            Value::String("restore-keys".into()),
            Value::String("${{ runner.os }}-cargo-".into()),
        );

        let mut step = Mapping::new();
        step.insert(
            Value::String("name".into()),
            Value::String("Restore cargo cache".into()),
        );
        step.insert(
            Value::String("uses".into()),
            Value::String("actions/cache@v4".into()),
        );
        step.insert(Value::String("with".into()), Value::Mapping(with));
        steps.push(step);
    }

    if job.packages.iter().any(|pkg| pkg == "node") {
        let mut with = Mapping::new();
        with.insert(
            Value::String("path".into()),
            Value::String("~/.pnpm-store\nnode_modules".into()),
        );
        with.insert(
            Value::String("key".into()),
            Value::String("${{ runner.os }}-pnpm-${{ hashFiles('**/pnpm-lock.yaml') }}".into()),
        );
        with.insert(
            Value::String("restore-keys".into()),
            Value::String("${{ runner.os }}-pnpm-".into()),
        );

        let mut step = Mapping::new();
        step.insert(
            Value::String("name".into()),
            Value::String("Restore pnpm cache".into()),
        );
        step.insert(
            Value::String("uses".into()),
            Value::String("actions/cache@v4".into()),
        );
        step.insert(Value::String("with".into()), Value::Mapping(with));
        steps.push(step);
    }

    steps
}

fn convert_run_step(run: &RunStep) -> Mapping {
    let mut mapping = Mapping::new();
    if !run.name.is_empty() {
        mapping.insert(
            Value::String("name".into()),
            Value::String(run.name.clone()),
        );
    }
    mapping.insert(
        Value::String("run".into()),
        Value::String(run.command.clone()),
    );
    if !run.env.is_empty() {
        mapping.insert(Value::String("env".into()), map_from_string_map(&run.env));
    }
    if !run.r#if.is_empty() {
        mapping.insert(Value::String("if".into()), Value::String(run.r#if.clone()));
    }
    mapping
}

fn convert_uses_step(uses: &UsesStep) -> Mapping {
    let mut mapping = Mapping::new();
    if !uses.name.is_empty() {
        mapping.insert(
            Value::String("name".into()),
            Value::String(uses.name.clone()),
        );
    }
    mapping.insert(
        Value::String("uses".into()),
        Value::String(uses.module.clone()),
    );
    if !uses.with.is_empty() {
        let mut with_mapping = Mapping::new();
        for (key, value) in &uses.with {
            with_mapping.insert(Value::String(key.clone()), parse_yaml_value(value));
        }
        mapping.insert(Value::String("with".into()), Value::Mapping(with_mapping));
    }
    if !uses.r#if.is_empty() {
        mapping.insert(Value::String("if".into()), Value::String(uses.r#if.clone()));
    }
    mapping
}

fn apply_condition(step: &mut Mapping, condition: &str) {
    let key = Value::String("if".into());
    if let Some(existing) = step.get(&key).and_then(Value::as_str) {
        let combined = format!("({existing}) && ({condition})");
        step.insert(key, Value::String(combined));
    } else {
        step.insert(
            Value::String("if".into()),
            Value::String(condition.to_string()),
        );
    }
}

fn parse_yaml_value(input: &str) -> Value {
    serde_yaml::from_str(input).unwrap_or_else(|_| Value::String(input.to_string()))
}

fn step_requires_node(step_type: &step::StepType) -> bool {
    match step_type {
        step::StepType::Uses(uses) => is_node_action(&uses.module),
        _ => false,
    }
}

fn is_node_action(module: &str) -> bool {
    module.starts_with("actions/cache@")
        || module.starts_with("actions/download-artifact@")
        || module.starts_with("actions/upload-artifact@")
        || module.starts_with("actions/github-script@")
        || module.starts_with("actions/configure-pages@")
        || module.starts_with("actions/deploy-pages@")
        || module.starts_with("actions/setup-node@")
}

fn map_from_string_map(map: &HashMap<String, String>) -> Value {
    let mut mapping = Mapping::new();
    for (key, value) in map {
        mapping.insert(Value::String(key.clone()), Value::String(value.clone()));
    }
    Value::Mapping(mapping)
}

fn make_diagnostic(workflow: &str, error: anyhow::Error) -> Diagnostic {
    Diagnostic {
        level: diagnostic::Level::Error as i32,
        code: "GITHUB_GENERATE_ERROR".to_string(),
        title: format!("Failed to generate workflow '{workflow}'"),
        message: error.to_string(),
        fix_hint: String::new(),
        loc: None,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn job_with_sources(id: &str, sources: &[&str]) -> JobDefinition {
        JobDefinition {
            id: id.to_string(),
            image: "rust:latest".to_string(),
            source_files: sources.iter().map(|s| s.to_string()).collect(),
            ..Default::default()
        }
    }

    #[test]
    fn builder_job_does_not_receive_download_step() {
        let job = job_with_sources("build_cigen", &[]);
        let rendered = render_job(&job, "ci", true).unwrap();

        let steps_key = Value::String("steps".into());
        let step_values: Vec<Value> = rendered
            .get(&steps_key)
            .and_then(Value::as_sequence)
            .cloned()
            .unwrap_or_default();

        let name_key = Value::String("name".into());
        let names: Vec<String> = step_values
            .iter()
            .filter_map(Value::as_mapping)
            .filter_map(|mapping| mapping.get(&name_key))
            .filter_map(Value::as_str)
            .map(str::to_string)
            .collect();

        assert!(names.contains(&"Checkout repository".to_string()));
        assert!(
            !names
                .iter()
                .any(|name| name == "Download cigen binary" || name == "Prepare cigen binary")
        );
    }
}
